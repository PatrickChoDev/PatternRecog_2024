{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train_df = pd.read_csv(train_url) #training set\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test_df = pd.read_csv(test_url) #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()\n",
    "# So Age, Cabin and Embarked have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "test_df.info()\n",
    "# So we will have to impute the missing values\n",
    "# Seem like Cabin missing TOO MUCH values, so we will drop it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill values with median !!FROM TRAINING DATA!!\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "\n",
    "# T8: Median age of training data is\n",
    "train_df[\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill values with most common value !!FROM TRAIN_dfING DATA!!\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].value_counts().idxmax())\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(train_df[\"Embarked\"].value_counts().idxmax())\n",
    "\n",
    "# T9: Most common port of embarked is\n",
    "train_df[\"Embarked\"].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare and PClass seems to be correlated, so we will use PClass to impute Fare\n",
    "test_df[\"Fare\"] = test_df[\"Fare\"].fillna(train_df.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_categories = dict([(k,i) for i,k in enumerate(train_df[\"Embarked\"].astype('category').cat.categories.tolist())])\n",
    "train_df[\"EmbarkedClass\"] = train_df[\"Embarked\"].map(embarked_categories)\n",
    "test_df[\"EmbarkedClass\"] = test_df[\"Embarked\"].map(embarked_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_categories = dict([(k,i) for i,k in enumerate(train_df[\"Sex\"].astype('category').cat.categories.tolist())])\n",
    "train_df[\"SexClass\"] = train_df[\"Sex\"].map(sex_categories)\n",
    "test_df[\"SexClass\"] = test_df[\"Sex\"].map(sex_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PassengerId        0\n",
       " Survived           0\n",
       " Pclass             0\n",
       " Name               0\n",
       " Sex                0\n",
       " Age                0\n",
       " SibSp              0\n",
       " Parch              0\n",
       " Ticket             0\n",
       " Fare               0\n",
       " Cabin            687\n",
       " Embarked           0\n",
       " EmbarkedClass      0\n",
       " SexClass           0\n",
       " dtype: int64,\n",
       " PassengerId        0\n",
       " Pclass             0\n",
       " Name               0\n",
       " Sex                0\n",
       " Age                0\n",
       " SibSp              0\n",
       " Parch              0\n",
       " Ticket             0\n",
       " Fare               0\n",
       " Cabin            327\n",
       " Embarked           0\n",
       " EmbarkedClass      0\n",
       " SexClass           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum(),test_df.isna().sum()\n",
    "\n",
    "# Data is quite cleaned!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  1., 22.,  2.],\n",
       "       [ 1.,  0., 38.,  0.],\n",
       "       [ 3.,  0., 26.,  2.],\n",
       "       ...,\n",
       "       [ 3.,  0., 28.,  2.],\n",
       "       [ 1.,  1., 26.,  0.],\n",
       "       [ 3.,  1., 32.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.array(train_df[[\"Pclass\",\"SexClass\",\"Age\",\"EmbarkedClass\"]].values,dtype=np.float32).reshape(-1,4)\n",
    "train_label = np.array(train_df[\"Survived\"].values,dtype=np.int8).reshape(-1,1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. ,  1. , 34.5,  1. ],\n",
       "       [ 3. ,  0. , 47. ,  2. ],\n",
       "       [ 2. ,  1. , 62. ,  1. ],\n",
       "       ...,\n",
       "       [ 3. ,  1. , 38.5,  2. ],\n",
       "       [ 3. ,  1. , 28. ,  2. ],\n",
       "       [ 3. ,  1. , 28. ,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array(test_df[[\"Pclass\",\"SexClass\",\"Age\",\"EmbarkedClass\"]].values,dtype=np.float32)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3cc55bf0b0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z): return 1/(1+np.exp(-z))\n",
    "\n",
    "x = np.linspace(-10,10,100)\n",
    "z = sigmoid(x)\n",
    "plt.plot(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  def  __init__(self,train_x,train_y,test_x,learning_rate=1e-3) -> None:\n",
    "    self.train_x = train_x\n",
    "    self.train_y = train_y\n",
    "    self.pred = np.zeros_like(train_y)\n",
    "    self.pred_class = np.zeros_like(train_y)\n",
    "    self.test_x = test_x\n",
    "    self.cost,self.grad = self.cost_function()\n",
    "    self.learning_rate = learning_rate\n",
    "    self.W = self.__random_init_param()\n",
    "    self.test_accuracies = []\n",
    "\n",
    "  def __random_init_param(self):\n",
    "    #size of X is [m, n] where m=sample, n=features\n",
    "    self.train_x = self.__add_bias(self.train_x)\n",
    "    W = np.random.randn(len(self.train_x[0]), 1) # +1 for Bias term\n",
    "    return W\n",
    "  \n",
    "  def __sigmoid(self,z): return 1/(1+np.exp(-z))\n",
    "\n",
    "  def __add_bias(self,X):\n",
    "    Bias = np.ones((len(X), 1))\n",
    "    res = np.concatenate((Bias, X), axis=1)\n",
    "    return res\n",
    "  \n",
    "  def cost_function(self):\n",
    "    if type(self.pred) == \"None\" : return None\n",
    "    m = len(self.train_y)\n",
    "    loss = np.dot(-self.train_y.T, np.log(self.__sigmoid(self.pred)+1e-10))-np.dot((1-self.train_y).T, np.log((1-self.__sigmoid(self.pred)+1e-10)))\n",
    "    cost = (1/m) * loss \n",
    "    grad = (1/m) * (np.dot(self.train_x.T, (self.__sigmoid(self.pred)-self.train_y)))\n",
    "    return cost.astype('float64'), grad.astype('float64')\n",
    "\n",
    "  def predict(self, X=None,sigmoid=True):\n",
    "    if X is None : X = self.train_x\n",
    "    h = np.dot(X, self.W)\n",
    "    return self.__sigmoid(h) if sigmoid else h\n",
    "  \n",
    "  def train_accuracy(self):\n",
    "    return np.squeeze(np.squeeze((sum(self.train_y == self.pred_class)/len(self.train_x))*100))\n",
    "  \n",
    "\n",
    "  def step(self):\n",
    "    #update parameters\n",
    "    self.W = self.W - self.learning_rate * self.grad\n",
    "    self.grad = 0\n",
    "  \n",
    "  def train(self,epoch=100,interuption_step=10,logging_step=None):\n",
    "    if logging_step is None : logging_step = epoch**0.5\n",
    "    loss_step = 0\n",
    "    for i in range(epoch):\n",
    "      self.pred = self.predict(None,False)\n",
    "      self.pred_class = np.where(self.__sigmoid(self.pred) >= 0.5, 1, 0)\n",
    "      cost, grad = self.cost_function()\n",
    "      self.grad = grad\n",
    "      self.step()\n",
    "      if i%logging_step == 0: print(f\"Epoch {i+1}/{epoch} : Train accuracy {self.train_accuracy()}%\")\n",
    "      if cost.item() < self.cost.item() : \n",
    "        loss_step = 0\n",
    "      else :\n",
    "        loss_step += 1\n",
    "        if loss_step == interuption_step :\n",
    "          print(f\"Loss is increasing, stop training at epoch {i+1}\")\n",
    "          break\n",
    "      self.cost = cost\n",
    "  \n",
    "  def test(self):\n",
    "    self.test_pred = self.predict(self.__add_bias(self.test_x))\n",
    "    return self.test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = LogisticRegression(train_data,train_label,test_data,0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000 : Train accuracy 37.82267115600449%\n",
      "Epoch 1001/1000000 : Train accuracy 63.2996632996633%\n",
      "Epoch 2001/1000000 : Train accuracy 63.2996632996633%\n",
      "Epoch 3001/1000000 : Train accuracy 68.79910213243546%\n",
      "Epoch 4001/1000000 : Train accuracy 71.49270482603815%\n",
      "Epoch 5001/1000000 : Train accuracy 71.49270482603815%\n",
      "Epoch 6001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 7001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 8001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 9001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 10001/1000000 : Train accuracy 78.90011223344557%\n",
      "Epoch 11001/1000000 : Train accuracy 80.24691358024691%\n",
      "Epoch 12001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 13001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 14001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 15001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 16001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 17001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 18001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 19001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 20001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 21001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 22001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 23001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 24001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 25001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 26001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 27001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 28001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 29001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 30001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 31001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 32001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 33001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 34001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 35001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 36001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 37001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 38001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 39001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 40001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 41001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 42001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 43001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 44001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 45001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 46001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 47001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 48001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 49001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 50001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 51001/1000000 : Train accuracy 78.56341189674522%\n",
      "Epoch 52001/1000000 : Train accuracy 78.67564534231201%\n",
      "Epoch 53001/1000000 : Train accuracy 78.78787878787878%\n",
      "Epoch 54001/1000000 : Train accuracy 78.78787878787878%\n",
      "Epoch 55001/1000000 : Train accuracy 78.78787878787878%\n",
      "Epoch 56001/1000000 : Train accuracy 78.78787878787878%\n",
      "Epoch 57001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 58001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 59001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 60001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 61001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 62001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 63001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 64001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 65001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 66001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 67001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 68001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 69001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 70001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 71001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 72001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 73001/1000000 : Train accuracy 79.68574635241302%\n",
      "Epoch 74001/1000000 : Train accuracy 79.68574635241302%\n",
      "Epoch 75001/1000000 : Train accuracy 79.7979797979798%\n",
      "Epoch 76001/1000000 : Train accuracy 79.7979797979798%\n",
      "Epoch 77001/1000000 : Train accuracy 79.7979797979798%\n",
      "Epoch 78001/1000000 : Train accuracy 79.7979797979798%\n",
      "Epoch 79001/1000000 : Train accuracy 79.91021324354658%\n",
      "Epoch 80001/1000000 : Train accuracy 79.91021324354658%\n",
      "Epoch 81001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 82001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 83001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 84001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 85001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 86001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 87001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 88001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 89001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 90001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 91001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 92001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 93001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 94001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 95001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 96001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 97001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 98001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 99001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 100001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 101001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 102001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 103001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 104001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 105001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 106001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 107001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 108001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 109001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 110001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 111001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 112001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 113001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 114001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 115001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 116001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 117001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 118001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 119001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 120001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 121001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 122001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 123001/1000000 : Train accuracy 79.34904601571269%\n",
      "Epoch 124001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 125001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 126001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 127001/1000000 : Train accuracy 79.57351290684625%\n",
      "Epoch 128001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 129001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 130001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 131001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 132001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 133001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 134001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 135001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 136001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 137001/1000000 : Train accuracy 79.46127946127946%\n",
      "Epoch 138001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 139001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 140001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 141001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 142001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 143001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 144001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 145001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 146001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 147001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 148001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 149001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 150001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 151001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 152001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 153001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 154001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 155001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 156001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 157001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 158001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 159001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 160001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 161001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 162001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 163001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 164001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 165001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 166001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 167001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 168001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 169001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 170001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 171001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 172001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 173001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 174001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 175001/1000000 : Train accuracy 79.2368125701459%\n",
      "Epoch 176001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 177001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 178001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 179001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 180001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 181001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 182001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 183001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 184001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 185001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 186001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 187001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 188001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 189001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 190001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 191001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 192001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 193001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 194001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 195001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 196001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 197001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 198001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 199001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 200001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 201001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 202001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 203001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 204001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 205001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 206001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 207001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 208001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 209001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 210001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 211001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 212001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 213001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 214001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 215001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 216001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 217001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 218001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 219001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 220001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 221001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 222001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 223001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 224001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 225001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 226001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 227001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 228001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 229001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 230001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 231001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 232001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 233001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 234001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 235001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 236001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 237001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 238001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 239001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 240001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 241001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 242001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 243001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 244001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 245001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 246001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 247001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 248001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 249001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 250001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 251001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 252001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 253001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 254001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 255001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 256001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 257001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 258001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 259001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 260001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 261001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 262001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 263001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 264001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 265001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 266001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 267001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 268001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 269001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 270001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 271001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 272001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 273001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 274001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 275001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 276001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 277001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 278001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 279001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 280001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 281001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 282001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 283001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 284001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 285001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 286001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 287001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 288001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 289001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 290001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 291001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 292001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 293001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 294001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 295001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 296001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 297001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 298001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 299001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 300001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 301001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 302001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 303001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 304001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 305001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 306001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 307001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 308001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 309001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 310001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 311001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 312001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 313001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 314001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 315001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 316001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 317001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 318001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 319001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 320001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 321001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 322001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 323001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 324001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 325001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 326001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 327001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 328001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 329001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 330001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 331001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 332001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 333001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 334001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 335001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 336001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 337001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 338001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 339001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 340001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 341001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 342001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 343001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 344001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 345001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 346001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 347001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 348001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 349001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 350001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 351001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 352001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 353001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 354001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 355001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 356001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 357001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 358001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 359001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 360001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 361001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 362001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 363001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 364001/1000000 : Train accuracy 79.12457912457911%\n",
      "Epoch 365001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 366001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 367001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 368001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 369001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 370001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 371001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 372001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 373001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 374001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 375001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 376001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 377001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 378001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 379001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 380001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 381001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 382001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 383001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 384001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 385001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 386001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 387001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 388001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 389001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 390001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 391001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 392001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 393001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 394001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 395001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 396001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 397001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 398001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 399001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 400001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 401001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 402001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 403001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 404001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 405001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 406001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 407001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 408001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 409001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 410001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 411001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 412001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 413001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 414001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 415001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 416001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 417001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 418001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 419001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 420001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 421001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 422001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 423001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 424001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 425001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 426001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 427001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 428001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 429001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 430001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 431001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 432001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 433001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 434001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 435001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 436001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 437001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 438001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 439001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 440001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 441001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 442001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 443001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 444001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 445001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 446001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 447001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 448001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 449001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 450001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 451001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 452001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 453001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 454001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 455001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 456001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 457001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 458001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 459001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 460001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 461001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 462001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 463001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 464001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 465001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 466001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 467001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 468001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 469001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 470001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 471001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 472001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 473001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 474001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 475001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 476001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 477001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 478001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 479001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 480001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 481001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 482001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 483001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 484001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 485001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 486001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 487001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 488001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 489001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 490001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 491001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 492001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 493001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 494001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 495001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 496001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 497001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 498001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 499001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 500001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 501001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 502001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 503001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 504001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 505001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 506001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 507001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 508001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 509001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 510001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 511001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 512001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 513001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 514001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 515001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 516001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 517001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 518001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 519001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 520001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 521001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 522001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 523001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 524001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 525001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 526001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 527001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 528001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 529001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 530001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 531001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 532001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 533001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 534001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 535001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 536001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 537001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 538001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 539001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 540001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 541001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 542001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 543001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 544001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 545001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 546001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 547001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 548001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 549001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 550001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 551001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 552001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 553001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 554001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 555001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 556001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 557001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 558001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 559001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 560001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 561001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 562001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 563001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 564001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 565001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 566001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 567001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 568001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 569001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 570001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 571001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 572001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 573001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 574001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 575001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 576001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 577001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 578001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 579001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 580001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 581001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 582001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 583001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 584001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 585001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 586001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 587001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 588001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 589001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 590001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 591001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 592001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 593001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 594001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 595001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 596001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 597001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 598001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 599001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 600001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 601001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 602001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 603001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 604001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 605001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 606001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 607001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 608001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 609001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 610001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 611001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 612001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 613001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 614001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 615001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 616001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 617001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 618001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 619001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 620001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 621001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 622001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 623001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 624001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 625001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 626001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 627001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 628001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 629001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 630001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 631001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 632001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 633001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 634001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 635001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 636001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 637001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 638001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 639001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 640001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 641001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 642001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 643001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 644001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 645001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 646001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 647001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 648001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 649001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 650001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 651001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 652001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 653001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 654001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 655001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 656001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 657001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 658001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 659001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 660001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 661001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 662001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 663001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 664001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 665001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 666001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 667001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 668001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 669001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 670001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 671001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 672001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 673001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 674001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 675001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 676001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 677001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 678001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 679001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 680001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 681001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 682001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 683001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 684001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 685001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 686001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 687001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 688001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 689001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 690001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 691001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 692001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 693001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 694001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 695001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 696001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 697001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 698001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 699001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 700001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 701001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 702001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 703001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 704001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 705001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 706001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 707001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 708001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 709001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 710001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 711001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 712001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 713001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 714001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 715001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 716001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 717001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 718001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 719001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 720001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 721001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 722001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 723001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 724001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 725001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 726001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 727001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 728001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 729001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 730001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 731001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 732001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 733001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 734001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 735001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 736001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 737001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 738001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 739001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 740001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 741001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 742001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 743001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 744001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 745001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 746001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 747001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 748001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 749001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 750001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 751001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 752001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 753001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 754001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 755001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 756001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 757001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 758001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 759001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 760001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 761001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 762001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 763001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 764001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 765001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 766001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 767001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 768001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 769001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 770001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 771001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 772001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 773001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 774001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 775001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 776001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 777001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 778001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 779001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 780001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 781001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 782001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 783001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 784001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 785001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 786001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 787001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 788001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 789001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 790001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 791001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 792001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 793001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 794001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 795001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 796001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 797001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 798001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 799001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 800001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 801001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 802001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 803001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 804001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 805001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 806001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 807001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 808001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 809001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 810001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 811001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 812001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 813001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 814001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 815001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 816001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 817001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 818001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 819001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 820001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 821001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 822001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 823001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 824001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 825001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 826001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 827001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 828001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 829001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 830001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 831001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 832001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 833001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 834001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 835001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 836001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 837001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 838001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 839001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 840001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 841001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 842001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 843001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 844001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 845001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 846001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 847001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 848001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 849001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 850001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 851001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 852001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 853001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 854001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 855001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 856001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 857001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 858001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 859001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 860001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 861001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 862001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 863001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 864001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 865001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 866001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 867001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 868001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 869001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 870001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 871001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 872001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 873001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 874001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 875001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 876001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 877001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 878001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 879001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 880001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 881001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 882001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 883001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 884001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 885001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 886001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 887001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 888001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 889001/1000000 : Train accuracy 79.01234567901234%\n",
      "Epoch 890001/1000000 : Train accuracy 79.01234567901234%\n",
      "Loss is increasing, stop training at epoch 890482\n"
     ]
    }
   ],
   "source": [
    "r.train(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44872295]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 342)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.pred_class[r.pred_class > 0.5]),len(r.train_y[r.train_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(79.01234568)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.train_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = r.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = np.where(res>=0.5,1,0)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 256)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[res > 0.5]),len(res[res < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>EmbarkedClass</th>\n",
       "      <th>SexClass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q   \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S   \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q   \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S   \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S   \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...   \n",
       "413    male  28.0      0      0           A.5. 3236    8.0500   NaN        S   \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
       "416    male  28.0      0      0              359309    8.0500   NaN        S   \n",
       "417    male  28.0      1      1                2668   22.3583   NaN        C   \n",
       "\n",
       "     EmbarkedClass  SexClass  Survived  \n",
       "0                1         1         0  \n",
       "1                2         0         0  \n",
       "2                1         1         0  \n",
       "3                2         1         0  \n",
       "4                2         0         1  \n",
       "..             ...       ...       ...  \n",
       "413              2         1         0  \n",
       "414              0         0         1  \n",
       "415              2         1         0  \n",
       "416              2         1         0  \n",
       "417              0         1         0  \n",
       "\n",
       "[418 rows x 14 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Survived\"] = pred_class\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
